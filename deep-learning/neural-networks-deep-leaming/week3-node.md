<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

### Neural network

input : \\(X\\)

$$ z^{[1]} = w^{[1]T}*X+b^{[1]} $$
$$ a^{[1]} = sigma(z^{[1]}) $$
$$ z^{[2]} = w^{[2]T}*a^{[1]}+b^{2} $$
$$ a^{[2]} = sigma(z^{[2]})$$

#### activation function 
 - tanh(z)
 - sigma(z)
 - RuLU(z)

